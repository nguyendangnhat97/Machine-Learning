# -*- coding: utf-8 -*-
"""
Created on Mon Oct 11 09:57:38 2021

@author: Admin
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#sigmoid function
def sigmoid(x):
    return 1 / (1+np.exp(-x))
#read the data from csv file
data = pd.read_csv('dataset.csv').values
N, d = data.shape

x = data[:, 0:d-1].reshape(-1,d-1)
y= data[:, d-1].reshape(-1,1)
#visualize the data
plt.scatter(x[:10, 0], x[:10, 1], c='red', edgecolors='none', s=30, label='accept')
plt.scatter(x[10:, 0], x[10:, 1], c='blue', edgecolors='none', s=30, label='reject')
plt.legend(loc=1)
plt.xlabel('salary')
plt.ylabel('experience year')
#add a column '1' to x
x = np.hstack((np.ones((N, 1)), x))
w = np.array([0., 0.1, 0.1]).reshape(-1,1)
#gradient descent to minimize loss function
numOfIteration = 7500
cost = np.zeros((numOfIteration, 1))
learning_rate = 0.01

for i in range(1, numOfIteration):
    y_predict = sigmoid(np.dot(x, w))
    cost[i] = -np.sum(np.multiply(y, np.log(y_predict)) + np.multiply((1-y), np.log(1-y_predict))) #loss function
    w -= learning_rate * np.dot(x.T, y_predict - y)
    print(cost[i])

#example
x1 = 4 #salary
x2 = 1.5 #experience year
y_predict = sigmoid(w[0]+w[1]*x1 + w[2]*x2)
print('probability: ', y_predict)





















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































